{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mismayil/opt/anaconda3/envs/optml-project/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170499072it [00:24, 6949836.13it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "cifar = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([125.30691805, 122.95039414, 113.86538318]),\n",
       " array([62.99321928, 62.08870764, 66.70489964]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CIFAR_MEAN = cifar.data.mean(axis=(0,1,2))\n",
    "CIFAR_STD = cifar.data.std(axis=(0,1,2))\n",
    "CIFAR_MEAN, CIFAR_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(CIFAR_MEAN, CIFAR_STD)\n",
    "    ])), batch_size=128, shuffle=False)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(datasets.CIFAR10(\"data\", train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(CIFAR_MEAN, CIFAR_STD)\n",
    "    ])), batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(next(iter(train_loader))[0][2].permute(1, 2, 0) * CIFAR_STD + CIFAR_MEAN)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4 * 4 * 50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class CIFAR10Classifier(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-4, optimizer=\"adam\"):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = CIFAR10Model()\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        self.metrics = {\n",
    "            \"accuracy\": {\n",
    "                \"train\": torchmetrics.Accuracy(),\n",
    "                \"val\": torchmetrics.Accuracy()\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def step(self, batch, step_name=\"train\"):\n",
    "        X, y = batch\n",
    "        outputs = self.model(X)\n",
    "        loss = self.criterion(outputs, y)\n",
    "        preds = self.forward(X)\n",
    "        metric = self.metrics[\"accuracy\"][step_name]\n",
    "        metric.update(preds.cpu(), y.cpu())\n",
    "        metric_val = metric.compute()\n",
    "        self.log(f\"{step_name}_loss\", loss, on_epoch=True)\n",
    "        self.log(f\"{step_name}_accuracy\", metric_val, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        return self.model(X)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        return self.forward(X)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.hparams.optimizer == \"sgd\":\n",
    "            return optim.SGD(self.parameters(), lr=self.hparams.lr)\n",
    "        elif self.hparams.optimizer == \"rmsprop\":\n",
    "            return optim.RMSprop(self.parameters(), lr=self.hparams.lr)\n",
    "        elif self.hparams.optimizer == \"adagrad\":\n",
    "            return optim.Adagrad(self.parameters(), lr=self.hparams.lr)\n",
    "        \n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/mete/ZO-L2L/wandb/run-20220610_133257-31f2xjdr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mismayil/optml-project/runs/31f2xjdr\" target=\"_blank\">emnist-classifier</a></strong> to <a href=\"https://wandb.ai/mismayil/optml-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type            | Params\n",
      "----------------------------------------------\n",
      "0 | model     | EMnistConvModel | 431 K \n",
      "1 | criterion | NLLLoss         | 0     \n",
      "----------------------------------------------\n",
      "431 K     Trainable params\n",
      "0         Non-trainable params\n",
      "431 K     Total params\n",
      "1.724     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983cc42b0cbc4083a853e43052fe6c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/optml/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/root/.conda/envs/optml/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c948785a544ef8b774ce5062aa1529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f604581257bc4903b0484abf6eab632c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a488484446b54416936482bfd96723c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d4ee06e7da4d31a65ffa03d39d16ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>train_accuracy_epoch</td><td>▁█</td></tr><tr><td>train_accuracy_step</td><td>▁▃▅▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▁</td></tr><tr><td>train_loss_step</td><td>█▃▃▂▂▁▂▂▂▁▁▂▁▂▁▁▁▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>val_accuracy</td><td>▁█</td></tr><tr><td>val_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train_accuracy_epoch</td><td>0.96862</td></tr><tr><td>train_accuracy_step</td><td>0.97428</td></tr><tr><td>train_loss_epoch</td><td>0.0402</td></tr><tr><td>train_loss_step</td><td>0.03052</td></tr><tr><td>trainer/global_step</td><td>3749</td></tr><tr><td>val_accuracy</td><td>0.98313</td></tr><tr><td>val_loss</td><td>0.0317</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">emnist-classifier</strong>: <a href=\"https://wandb.ai/mismayil/optml-project/runs/31f2xjdr\" target=\"_blank\">https://wandb.ai/mismayil/optml-project/runs/31f2xjdr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220610_133257-31f2xjdr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"optml-project\", name=f\"cifar10-adam\")\n",
    "\n",
    "model = CIFAR10Classifier()\n",
    "trainer = pl.Trainer(default_root_dir=\"models/cifar10\", max_epochs=NUM_EPOCHS, logger=wandb_logger, accelerator=\"gpu\")\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"ckpt/attack_model/emnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "emnist_model_dict = OrderedDict({name.replace(\"model.\", \"\"): parameter for name, parameter in model.state_dict().items()})\n",
    "torch.save(emnist_model_dict, \"ckpt/attack_model/emnist_cnn.pt\")\n",
    "# for name, parameter in model.state_dict().items():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/root/.conda/envs/optml/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0008ac648a7d4df29ea537fada40047f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1875it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = EMNISTClassifier(lr=1e-4)\n",
    "model.load_state_dict(torch.load(\"ckpt/attack_model/emnist_cnn.pt\"))\n",
    "preds = trainer.predict(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40000, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_targets = []\n",
    "\n",
    "for _, y in val_loader:\n",
    "    val_targets.append(y)\n",
    "\n",
    "val_targets = torch.cat(val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9899)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == val_targets).sum() / len(val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_indices = torch.where(preds == val_targets)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 39997, 39998, 39999])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(\"data/emnist_correct/label_correct_index.npy\", \"wb\") as f:\n",
    "    np.save(f, correct_indices.numpy())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59d2a09fbe8c3c145fa6cc268c78f8a343997643e35868cecb44e84cd20c2cea"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('optml-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
